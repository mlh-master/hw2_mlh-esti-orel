{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "import random\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import plot_confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import hinge_loss\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing CSV to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = Path.cwd().joinpath('HW2_data.csv')\n",
    "Diab = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Of the 565 patients, we want to remove patients with at least 3 NaN.\n",
    "#### Patients with 2 nan values or less: we will have the NaNs replaced with random values from a feature values (column).\n",
    "#### Since this is a small number of patients from the group examined, if a bias is created it is very small, and yet the given data is large enough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\envs\\bm-336546\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2898\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Age'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-05b33644364d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mclean_Diab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnan2value_random\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDiab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-05b33644364d>\u001b[0m in \u001b[0;36mnan2value_random\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mbank_for_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mbank_for_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbank_for_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbank_for_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\bm-336546\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\bm-336546\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\bm-336546\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1059\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\bm-336546\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3491\u001b[0m             \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3493\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3495\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\bm-336546\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2898\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2900\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2902\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Age'"
     ]
    }
   ],
   "source": [
    "def nan2value_random(df):\n",
    "    df = df.dropna(axis=0, thresh=15)\n",
    "    for col in df:\n",
    "        bank_for_col = df.loc[col].dropna()\n",
    "        bank_for_col = np.random.choice(bank_for_col, size=len(df.loc[col]))\n",
    "        df[col] = df.loc[col].fillna(pd.Series(bank_for_col))\n",
    "\n",
    "\n",
    "    return df\n",
    "clean_Diab = nan2value_random(Diab) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a test-train split of 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_Diab[['Age','Gender','Increased Urination','Increased Thirst','Sudden Weight Loss','Weakness','Increased Hunger','Genital Thrush','Visual Blurring','Itching','Irritability','Delayed Healing','Partial Paresis','Muscle Stiffness','Hair Loss','Obesity','Family History']]\n",
    "y= clean_Diab[['Diagnosis']]\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 10, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           0        1         2\n",
      "Positive Feature      %Train    %Test    %Delta\n",
      "Gender               37.4165  31.8584   5.55807\n",
      "Increased Urination  48.7751  47.7876  0.987445\n",
      "Increased Thirst     43.8753  44.2478  0.372509\n",
      "Sudden Weight Loss   40.5345  44.2478   3.71327\n",
      "Weakness             57.0156   59.292   2.27645\n",
      "Increased Hunger     45.2116  44.2478  0.963794\n",
      "Genital Thrush       19.5991  30.9735   11.3743\n",
      "Visual Blurring      45.2116  43.3628   1.84875\n",
      "Itching              47.8842  49.5575   1.67334\n",
      "Irritability          23.608  23.8938  0.285787\n",
      "Delayed Healing      46.7706  45.1327   1.63786\n",
      "Partial Paresis      43.6526   39.823   3.82955\n",
      "Muscle Stiffness     36.7483  35.3982    1.3501\n",
      "Hair Loss            35.6347  36.2832  0.648442\n",
      "Obesity              17.5947  14.1593   3.43536\n",
      "Diagnosis            48.9978  55.7522   6.75444\n"
     ]
    }
   ],
   "source": [
    "##create binary train, test DataFrames (except for age feature):\n",
    "X_train_binary = X_train.replace(['Yes','Female','Positive'],value = 1)\n",
    "X_train_binary = X_train_binary.replace(['No','Male','Negative'],value = 0)\n",
    "x_test_binary = x_test.replace(['Yes','Female','Positive'],value = 1)\n",
    "x_test_binary = x_test_binary.replace(['No','Male','Negative'],value = 0)\n",
    "#create a dictionary with features and values as %train, %test, %delta\n",
    "list_train = [None]*16\n",
    "list_test = [None]*16\n",
    "delta = [None]*16\n",
    "features_dictionary={}\n",
    "features_dictionary['Positive Feature']=['%Train', '%Test', '%Delta']\n",
    "for i in range(0,16):\n",
    "    list_train[i] = X_train_binary.iloc[:,i+1].sum()*(100/len(X_train_binary))\n",
    "    list_test[i] = x_test_binary.iloc[:,i+1].sum()*(100/len(x_test_binary))\n",
    "    delta[i] = abs(list_train[i]-list_test[i])\n",
    "    features_dictionary[clean_Diab.columns[i+1]]= [list_train[i], list_test[i], delta[i]]\n",
    "\n",
    "df_features_dictionary = pd.DataFrame.from_dict(features_dictionary).T\n",
    "print(df_features_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary that shows the relationship between feature and label.\n",
    "#keys: 1.positive feature 2.negative feature\n",
    "#values for each key: 1. number of positive diagnosis 2.number of negative diagnosis\n",
    "#We create a bar plot after defining a dictionary for a feature\n",
    "label_feature_relationship={}\n",
    "label_feature_relationship['Female'] = {}\n",
    "label_feature_relationship['Female']['Positive'] = len(clean_Diab[(clean_Diab.Gender.str.contains('Female')) & (clean_Diab.Diagnosis.str.contains('Positive'))])\n",
    "label_feature_relationship['Female']['Negative'] = len(clean_Diab[(clean_Diab.Gender.str.contains('Female')) & (clean_Diab.Diagnosis.str.contains('Negative'))])\n",
    "\n",
    "label_feature_relationship['Male'] = {}\n",
    "label_feature_relationship['Male']['Positive'] = len(clean_Diab[(clean_Diab.Gender.str.contains('Male')) & (clean_Diab.Diagnosis.str.contains('Positive'))])\n",
    "label_feature_relationship['Male']['Negative'] = len(clean_Diab[(clean_Diab.Gender.str.contains('Male')) & (clean_Diab.Diagnosis.str.contains('Negative'))])\n",
    "\n",
    "df = pd.DataFrame.from_dict(label_feature_relationship)\n",
    "df = df.T\n",
    "df.plot.bar(rot=0, title='Gender')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "for i in range(2,16):\n",
    "    title = clean_Diab.columns[i]\n",
    "    label_feature_relationship = {}\n",
    "    label_feature_relationship[\"Has %s\" %title] = {}\n",
    "    label_feature_relationship[\"Has %s\" %title]['Positive'] = len(clean_Diab[(clean_Diab[title].str.contains('Yes')) & clean_Diab.Diagnosis.str.contains('Positive')])\n",
    "    label_feature_relationship[\"Has %s\" %title]['Negative'] = len(clean_Diab[(clean_Diab[title].str.contains('Yes')) & clean_Diab.Diagnosis.str.contains('Negative')])\n",
    "    label_feature_relationship[\"No %s\" % title] = {}\n",
    "    label_feature_relationship[\"No %s\" % title]['Positive'] = len(clean_Diab[(clean_Diab[title].str.contains('No')) & clean_Diab.Diagnosis.str.contains('Positive')])\n",
    "    label_feature_relationship[\"No %s\" % title]['Negative'] = len(clean_Diab[(clean_Diab[title].str.contains('No')) & clean_Diab.Diagnosis.str.contains('Negative')])\n",
    "    df = pd.DataFrame.from_dict(label_feature_relationship)\n",
    "    df = df.T\n",
    "    df.plot.bar(rot=0, title=title)\n",
    "    plt.ylabel('Counts')\n",
    "    plt.show()\n",
    "\n",
    "label_feature_relationship = {}\n",
    "label_feature_relationship[\"Has Family History\"] = {}\n",
    "label_feature_relationship[\"Has Family History\"]['Positive'] = len(clean_Diab.loc[clean_Diab['Family History']==1 & clean_Diab.Diagnosis.str.contains('Positive')])\n",
    "label_feature_relationship[\"Has Family History\"]['Negative'] = len(clean_Diab.loc[clean_Diab['Family History']==1 & clean_Diab.Diagnosis.str.contains('Negative')])\n",
    "label_feature_relationship[\"No Family History\"] = {}\n",
    "label_feature_relationship[\"No Family History\"]['Positive'] = len(clean_Diab.loc[clean_Diab['Family History']==0 & clean_Diab.Diagnosis.str.contains('Positive')])\n",
    "label_feature_relationship[\"No Family History\"]['Negative'] = len(clean_Diab.loc[clean_Diab['Family History']==0 & clean_Diab.Diagnosis.str.contains('Negative')])\n",
    "df = pd.DataFrame.from_dict(label_feature_relationship)\n",
    "df = df.T\n",
    "df.plot.bar(rot=0, title='Family History')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Is there an age from which the chance of getting sick increases significantly?- A histogram is drawn showing a connection between age and a positive diagnosis:\n",
    "ax = clean_Diab.hist(column='Age', bins= 100, figsize=(12,8), color='#86bf91', zorder=2, rwidth=0.9)\n",
    "ax = ax[0]\n",
    "for x in ax:\n",
    "    x.set_ylabel(\"Count\", labelpad=20, weight='bold', size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Compare age histogram for positive diagnosis and age histogram for negative diagnosis:\n",
    "positive_age_series = clean_Diab[clean_Diab.Diagnosis.str.contains('Positive')]['Age']\n",
    "negative_age_series = clean_Diab[clean_Diab.Diagnosis.str.contains('Negative')]['Age']\n",
    "plt.hist(positive_age_series, bins=100, label='Positive Diagnosis')\n",
    "plt.hist(negative_age_series, bins=100, label='Negative Diagnosis')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Pie chart of positive/negative diagnosis\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "for idx, value in enumerate(clean_Diab['Diagnosis']):\n",
    "    if value =='Positive':\n",
    "        positive_count +=1\n",
    "    else:\n",
    "        negative_count +=1\n",
    "labels = ('Positive', 'Negative')\n",
    "sizes = [positive_count, negative_count]\n",
    "colors = ['lightcoral', 'yellowgreen']\n",
    "figureObject, axesObject = plt.subplots()\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title(\"Positive and negative diagnosis percentages\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding our data as one hot vectors\n",
    "X_binary = X.replace(['Yes','Female','Positive'],value = 1)\n",
    "X_binary = X_binary.replace(['No','Male','Negative'],value = 0)\n",
    "enc = OneHotEncoder( sparse=False,handle_unknown='ignore')\n",
    "onehotvector=enc.fit_transform(X_binary.drop(['Age'], axis=1))\n",
    "print(onehotvector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qusetion 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K cross fold+ SVM ( linear for 'svm_kernel':['linear'], non linear for 'svm_kernel':['rbf'])\n",
    "# Linear SVM model\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=10, shuffle=True)\n",
    "svc = SVC(probability=True)\n",
    "C = np.array([0.001, 0.01, 1, 10, 100, 1000])\n",
    "pipe = Pipeline(steps=[('scale', StandardScaler()), ('svm', svc)])\n",
    "svm_lin = GridSearchCV(estimator=pipe,\n",
    "             param_grid={'svm_kernel':['linear'], 'svm_C':C}, scoring=['roc_auc'],  cv=skf, refit='roc_auc', verbose=3, return_train_score=True)\n",
    "\n",
    "svm_lin.fit(X_train_binary, Y_train)\n",
    "best_svm_lin = svm_lin.best_estimator_\n",
    "\n",
    "\n",
    "calc_TN = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[0, 0]\n",
    "calc_FP = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[0, 1]\n",
    "calc_FN = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[1, 0]\n",
    "calc_TP = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[1, 1]\n",
    "\n",
    "y_pred_test_lin = best_svm_lin.predict(x_test_binary)\n",
    "y_pred_proba_test_lin = best_svm_lin.predict_proba(x_test_binary)\n",
    "lin_loss = hinge_loss(y_test, y_pred_proba_test_lin[:,1])\n",
    "LSVM_score = roc_auc_score(y_test, y_pred_proba_test_lin[:,1])\n",
    "\n",
    "TN = calc_TN(y_test, y_pred_test_lin)\n",
    "FP = calc_FP(y_test, y_pred_test_lin)\n",
    "FN = calc_FN(y_test, y_pred_test_lin)\n",
    "TP = calc_TP(y_test, y_pred_test_lin)\n",
    "Se = TP/(TP+FN)\n",
    "Sp = TN/(TN+FP)\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "Acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "F1 = (2*Se*PPV)/(Se+PPV)\n",
    "\n",
    "#Non- linear SVM (RBF Kernel):\n",
    "pipe_rbf = Pipeline(steps=[('scale', StandardScaler()), ('svm', svc)])\n",
    "svm_rbf = GridSearchCV(estimator=pipe,\n",
    "             param_grid={'svm_kernel':['rbf'], 'svm_C':C}, scoring=['roc_auc'],  cv=skf, refit='roc_auc', verbose=3, return_train_score=True)\n",
    "\n",
    "svm_rbf.fit(X_train_binary, Y_train)\n",
    "best_svm_rbf = svm_rbf.best_estimator_\n",
    "\n",
    "y_pred_test_rbf = best_svm_rbf.predict(x_test_binary)\n",
    "y_pred_proba_test_rbf = best_svm_rbf.predict_proba(x_test_binary)\n",
    "rbf_loss = hinge_loss(y_test, y_pred_proba_test_rbf[:,1])\n",
    "rbf_SVM_score = roc_auc_score(y_test, y_pred_proba_test_rbf[:,1])\n",
    "\n",
    "TN_nl = calc_TN(y_test, y_pred_test_rbf)\n",
    "FP_nl = calc_FP(y_test, y_pred_test_rbf)\n",
    "FN_nl = calc_FN(y_test, y_pred_test_rbf)\n",
    "TP_nl = calc_TP(y_test, y_pred_test_rbf)\n",
    "Se_nl = TP/(TP+FN)\n",
    "Sp_nl = TN/(TN+FP)\n",
    "PPV_nl = TP/(TP+FP)\n",
    "NPV_nl = TN/(TN+FN)\n",
    "Acc_nl = (TP+TN)/(TP+TN+FP+FN)\n",
    "F1_nl = (2*Se*PPV)/(Se+PPV)\n",
    "\n",
    "print(\"svm with  linear kernel:\")\n",
    "print(f'Sensitivity is {Se:.2f}')\n",
    "print(f'Specificity is {Sp:.2f}')\n",
    "print(f'PPV is {PPV:.2f}')\n",
    "print(f'NPV is {NPV:.2f}')\n",
    "print(f'Accuracy is {Acc:.2f}')\n",
    "print(f'F1 is {F1:.2f}')\n",
    "print(f'The Linear Loss is {lin_loss:.2f}')\n",
    "print(f'AUC is {LSVM_score:.2f}')\n",
    "print(\"\\n svm with rbf kernel:\")\n",
    "print(f' Sensitivity is {Se_nl:.2f}')\n",
    "print(f' Specificity is {Sp_nl:.2f}')\n",
    "print(f' PPV is {PPV_nl:.2f}')\n",
    "print(f' NPV is {NPV_nl:.2f}')\n",
    "print(f' Accuracy is {Acc_nl:.2f}')\n",
    "print(f' F1 is {F1_nl:.2f}')\n",
    "print(f' Loss is {rbf_loss:.2f}')\n",
    "print(f' AUC is {rbf_SVM_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6- Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Network\n",
    "clf = rfc(n_estimators=10)\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train_binary)\n",
    "clf.fit(X_train_scale, Y_train)\n",
    "w_ = clf.feature_importances_\n",
    "features=['Age','Gender','Increased Urination','Increased Thirst','Sudden Weight Loss','Weakness','Increased Hunger','Genital Thrush','Visual Blurring','Itching','Irritability','Delayed Healing','Partial Paresis','Muscle Stiffness','Hair Loss','Obesity','Family History']\n",
    "x = np.arange(len(features))\n",
    "\n",
    "plt.bar(x, w_,0.5, color='c')\n",
    "plt.xticks(x,features,rotation=90);\n",
    "plt.ylabel(\"weights\", fontsize=12)\n",
    "plt.title(\"Feature Weights- RFC\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
